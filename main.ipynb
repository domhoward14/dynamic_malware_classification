{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup(df):\n",
    "    api_lookup = {\"unknown\": 0}\n",
    "\n",
    "    # make flat dataset to create lookup map with\n",
    "    statements = df.str.split().apply(pd.Series)\n",
    "    for v in pd.DataFrame(statements).stack():\n",
    "        api_lookup[v] = 0\n",
    "\n",
    "    i = 0\n",
    "    for v, k in enumerate(api_lookup):\n",
    "        api_lookup[k] = i\n",
    "        i += 1\n",
    "\n",
    "    return api_lookup\n",
    "\n",
    "\n",
    "def create_encoded_api_statements(df_x):\n",
    "    api_call_statements = df_x.str.split().apply(pd.Series)\n",
    "    api_lookup = create_lookup(df_x)\n",
    "\n",
    "    # to avoid unexpected behavior make a new copy of the df for modifying\n",
    "    api_call_statements_copy = api_call_statements.copy()\n",
    "\n",
    "    for idx, row in api_call_statements.iterrows():\n",
    "        for col_idx, value in enumerate(row):\n",
    "            if value in api_lookup:\n",
    "                api_call_statements_copy.at[idx, col_idx] = api_lookup[value]\n",
    "            else:\n",
    "                api_call_statements_copy.at[idx, col_idx] = 0\n",
    "\n",
    "    return api_call_statements_copy, api_lookup\n",
    "\n",
    "\n",
    "def create_frequency_list(df_x):\n",
    "    freq_list = []\n",
    "\n",
    "    for index, row in pd.DataFrame(df_x).iterrows():\n",
    "        freq_list.append(row.value_counts().to_dict())\n",
    "\n",
    "    return freq_list\n",
    "\n",
    "\n",
    "def create_freq_count_df(freq_list: list) -> pd.DataFrame:\n",
    "    freq_count_df = pd.DataFrame(0, index=range(40566), columns=range(251))\n",
    "    freq_count_df_copy = freq_count_df.copy()\n",
    "\n",
    "    for i, row in freq_count_df.iterrows():\n",
    "        for j in freq_list[i]:\n",
    "            freq_count_df_copy.iloc[i,j] = freq_list[i][j]\n",
    "\n",
    "    return freq_count_df_copy\n",
    "\n",
    "\n",
    "def write_lookup_hashmap_to_file(lookup_hashmap):\n",
    "    with open('api_calls_lookup.txt', 'w') as file:\n",
    "        for index, key in enumerate(lookup_hashmap):\n",
    "            encoded_key = f'{key}={index}'\n",
    "            file.write(encoded_key + '\\n')\n",
    "\n",
    "\n",
    "def train_and_test_nn(X: np.ndarray, y: Iterable, num_of_classes: int, cls_type: str, filename=None) -> None:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=X_train.shape[-1], activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(9, activation='tanh'))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=3, monitor='val_loss', restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)    \n",
    "\n",
    "    # Plot the accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert predictions to binary values\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    y_pred_categories = np.argmax(y_pred_binary, axis=1)\n",
    "\n",
    "    report = classification_report(y_test, y_pred_categories)\n",
    "    print(report)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred_categories)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    if filename:\n",
    "        with open(filename, 'a') as file:\n",
    "            file.write(f\"\\n\\n{cls_type}:\\n\")\n",
    "            file.write(\"\\n\\nAccuracy: \" + str(accuracy) + \"\\n\")\n",
    "            file.write(\"Classification Report:\\n\" + str(report) + \"\\n\")\n",
    "            file.write(\"Confusion Matrix:\\n\" + str(cm) + \"\\n\")\n",
    "\n",
    "    return y_test\n",
    "\n",
    "def train_and_test_data(model, df_x_onehot: np.ndarray, df_y: Iterable, cls_type: str, filename=None) -> None:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_x_onehot, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Calculate precision, recall and F1-score\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    if filename:\n",
    "        with open(filename, 'a') as file:\n",
    "            file.write(f\"\\n\\n{cls_type}:\\n\")\n",
    "            file.write(\"Accuracy: \" + str(accuracy) + \"\\n\")\n",
    "            file.write(\"Classification Report:\\n\" + str(report) + \"\\n\")\n",
    "            file.write(\"Confusion Matrix:\\n\" + str(cm) + \"\\n\")\n",
    "\n",
    "\n",
    "# Perform feature selection using Random Forest\n",
    "def perform_feature_selection(X: pd.DataFrame, y: pd.Series) -> tuple[np.ndarray, np.ndarray]:\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    feature_selector = SelectFromModel(rf)\n",
    "    X_new = feature_selector.fit_transform(X, y)\n",
    "\n",
    "    selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "    return X_new, selected_feature_indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "oli_df = pd.read_csv(\"data/Oliveria.csv\")\n",
    "cat_df = pd.read_csv(\"data/CatakOriginal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "oli_df_x = oli_df[\"api\"]\n",
    "oli_df_y = oli_df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_x = cat_df[\"api\"]\n",
    "cat_df_y = cat_df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all the data prep work\n",
    "encoded_api_stmts_oli_df_x, api_lookup = create_encoded_api_statements(oli_df_x)\n",
    "write_lookup_hashmap_to_file(api_lookup)\n",
    "oli_freq_list = create_frequency_list(encoded_api_stmts_oli_df_x)\n",
    "oli_df_x_processed = create_freq_count_df(oli_freq_list)\n",
    "\n",
    "# encode targets\n",
    "oli_df_y_ints = LabelEncoder().fit_transform(oli_df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file to store all output\n",
    "current_date = datetime.datetime.now().strftime(\"%m-%d-%y\")\n",
    "results = f\"results/output_{current_date}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction via feature selection using RF\n",
    "oli_df_x_processed_selected, indices = perform_feature_selection(oli_df_x_processed, oli_df_y_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "rf = RandomForestClassifier()\n",
    "train_and_test_data(rf, oli_df_x_processed_selected, oli_df_y_ints, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb\n",
    "#xc = xgb.XGBClassifier()\n",
    "#train_and_test_data(xc, oli_df_x_onehot_selected, oli_df_y_ints, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn\n",
    "train_and_test_nn(oli_df_x_processed_selected, oli_df_y_ints, 9, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn\n",
    "train_and_test_nn(oli_df_x_processed_selected, oli_df_y_ints, 9, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
